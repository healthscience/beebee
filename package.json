{
  "name": "beebee-agent",
  "version": "0.2.0",
  "description": "BeeBee TINY agent  LLM service using node-llama-cpp",
  "main": "src/index.js",
  "type": "module",
  "scripts": {
    "start": "node examples/basic.js",
    "test": "vitest",
    "test:ui": "vitest --ui",
    "test:coverage": "vitest --coverage",
    "dev": "node --watch examples/basic.js",
    "example": "node examples/basic.js",
    "example:stream": "node examples/streaming.js",
    "example:events": "node examples/events.js",
    "example:integration": "node examples/beebee-ai-integration.js",
    "check-model": "node examples/check-model-path.js",
    "example:download": "node examples/model-download-flow.js"
  },
  "dependencies": {
    "node-llama-cpp": "^3.0.0",
    "express": "^4.18.2",
    "ws": "^8.14.2",
    "cors": "^2.8.5",
    "node-fetch": "^3.3.2"
  },
  "devDependencies": {
    "@types/node": "^20.0.0",
    "vitest": "^1.0.0",
    "@vitest/ui": "^1.0.0",
    "@vitest/coverage-v8": "^1.0.0"
  },
  "engines": {
    "node": ">=18.0.0"
  },
  "keywords": [
    "llm",
    "llama",
    "ai",
    "beebee"
  ],
  "author": "@aboynejames",
  "license": "GPL-3.0"
}
